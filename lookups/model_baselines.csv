model_id,avg_response_time,avg_token_count,avg_confidence,std_response_time,std_token_count,std_confidence,baseline_date,sample_count
gpt-4-turbo,2.1,145,0.89,0.8,25,0.12,2025-06-01,1500
gpt-3.5-turbo,1.3,120,0.85,0.5,20,0.15,2025-06-01,2000
claude-3-sonnet,1.8,160,0.91,0.6,30,0.08,2025-06-01,1200
claude-3-haiku,0.9,95,0.82,0.3,15,0.18,2025-06-01,1800
llama-2-70b,3.2,180,0.87,1.2,35,0.14,2025-06-01,800
gemini-pro,2.5,155,0.88,0.9,28,0.11,2025-06-01,1100
