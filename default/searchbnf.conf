[driftdetect-command]
syntax = driftdetect field=<field> (baseline_file=<string>)? (threshold=<float>)? (window_size=<int>)?
shortdesc = Detect semantic drift in LLM outputs
description = \
    Analyzes semantic drift in text fields by comparing against baseline embeddings. \
    Calculates drift scores and identifies when model outputs deviate from expected patterns.
usage = public
example1 = | driftdetect field=response baseline_file="model_baselines.csv" threshold=0.8
comment1 = Detect drift in response field using baseline file with 0.8 similarity threshold
example2 = | driftdetect field=response window_size=50
comment2 = Detect drift comparing against rolling window of 50 recent samples
related = semanticcompare, llmmetrics
tags = llm, drift, semantic, monitoring

[semanticcompare-command]
syntax = semanticcompare field1=<field> field2=<field> (method=<string>)? (include_analysis=<bool>)?
shortdesc = Compare semantic similarity between text fields
description = \
    Compares semantic similarity between two text fields using various similarity metrics. \
    Provides detailed analysis of semantic relationships and text variations.
usage = public
example1 = | semanticcompare field1=prompt field2=response method=cosine
comment1 = Compare prompt and response similarity using cosine similarity
example2 = | semanticcompare field1=original_text field2=modified_text include_analysis=true
comment2 = Compare texts with detailed semantic analysis
related = driftdetect, llmmetrics
tags = llm, semantic, similarity, comparison

[llmmetrics-command]
syntax = llmmetrics response_field=<field> (prompt_field=<field>)? (time_field=<field>)? (token_field=<field>)? (confidence_field=<field>)? (include_trends=<bool>)?
shortdesc = Calculate comprehensive LLM performance and quality metrics
description = \
    Calculates multiple quality and performance metrics for LLM interactions including \
    response quality, readability, coherence, performance timings, and trend analysis.
usage = public
example1 = | llmmetrics response_field=response time_field=response_time token_field=token_count
comment1 = Calculate basic performance metrics for LLM responses
example2 = | llmmetrics response_field=response prompt_field=prompt include_trends=true
comment2 = Calculate quality metrics with trend analysis
related = driftdetect, semanticcompare
tags = llm, metrics, performance, quality

[anomalydetect-command]
syntax = anomalydetect fields=<field-list> (method=<string>)? (threshold=<float>)? (window=<int>)?
shortdesc = Detect anomalies in LLM behavior patterns
description = \
    Identifies statistical anomalies in LLM metrics and behavior patterns. \
    Uses various detection methods to flag unusual model performance.
usage = public
example1 = | anomalydetect fields="response_time,token_count" method=zscore threshold=2.0
comment1 = Detect anomalies in response time and token count using z-score method
example2 = | anomalydetect fields="confidence_score" window=100
comment2 = Detect confidence score anomalies using 100-sample rolling window
related = driftdetect, llmmetrics
tags = llm, anomaly, detection, monitoring

[baselinecompare-command]
syntax = baselinecompare metric=<field> baseline_field=<field> (threshold=<float>)? (comparison=<string>)?
shortdesc = Compare current metrics against established baselines
description = \
    Compares current LLM performance metrics against pre-established baseline values. \
    Identifies significant deviations from expected performance patterns.
usage = public
example1 = | baselinecompare metric=response_time baseline_field=avg_response_time threshold=25
comment1 = Compare response times against baseline with 25% threshold
example2 = | baselinecompare metric=confidence_score baseline_field=baseline_confidence comparison=percentage
comment2 = Compare confidence scores against baseline using percentage comparison
related = driftdetect, llmmetrics, anomalydetect
tags = llm, baseline, comparison, monitoring
